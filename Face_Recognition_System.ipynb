{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98623124",
   "metadata": {},
   "source": [
    "## Import lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "727f3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout,InputLayer\n",
    "# from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# for i in dir(tensorflow.keras.layers):\n",
    "#     m=i.lower()\n",
    "#     if m.startswith(\"i\"):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd95467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94f10787",
   "metadata": {},
   "source": [
    "# constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f109d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=cv.COLOR_BGR2GRAY\n",
    "font=cv.FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9bacb",
   "metadata": {},
   "source": [
    "## Generate DataSete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1f9016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\gamal\\AppData\\Local\\Temp\\ipykernel_12596\\2600257060.py:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "End....\n"
     ]
    }
   ],
   "source": [
    "def genrateDataset():\n",
    "    face_classfiler=cv.CascadeClassifier(\"datasets/haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray=cv.cvtColor(img,g)\n",
    "        faces=face_classfiler.detectMultiScale(gray,1.3,5)\n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face=img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    cap=cv.VideoCapture(0)\n",
    "    img_id=0\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face=cv.resize(face_cropped(frame),(200,200))\n",
    "            face=cv.cvtColor(face,g)\n",
    "            file_name_path=f\"datasets/imges/gamal.{img_id}.jpg\"\n",
    "            cv.imwrite(file_name_path,face)\n",
    "            cv.putText(face,str(img_id),(50,50),font,1,(0,255,0),2)\n",
    "            cv.imshow(\"face\",face)\n",
    "            print(img_id)\n",
    "            if cv.waitKey(1) & 0xFF ==ord(\"q\") or int(img_id)==20:\n",
    "                break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"End....\")\n",
    "genrateDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0affcac",
   "metadata": {},
   "source": [
    "## Createing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b7579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label(image_name):\n",
    "    name=image_name.split('.')[-3]\n",
    "    if name==\"person1\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name==\"person1\":\n",
    "        return np.array([0,1,0])\n",
    "    elif name==\"basma\":\n",
    "        return np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fdc78",
   "metadata": {},
   "source": [
    "## read images from dir and save in random array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde0750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    data=[]\n",
    "    for img in tqdm(os.listdir(\"datasets/imges/\")):\n",
    "        path=f\"datasets/imges/{img}\"\n",
    "        img_data=cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "        img_data=cv.resize(img_data,(50,50))\n",
    "        data.append([np.array(img_data),my_label(img)])\n",
    "    shuffle(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "# face=cv.resize(my_data()[0][0],(400,400))\n",
    "# cv.imshow(str(my_data()[0][1]),face)\n",
    "# k=cv.waitKey(0)\n",
    "\n",
    "# if k==27:\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e7750",
   "metadata": {},
   "source": [
    "## Create train and test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a1d4773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 1364.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_size=0.25\n",
    "data=my_data()\n",
    "test_dim=int(len(data)* test_size)\n",
    "traing_dim=(int(len(data)-test_dim))\n",
    "print(test_dim,traing_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ea4f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traing=data[:traing_dim]\n",
    "test=data[traing_dim:]\n",
    "len(traing)+len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff9fe7",
   "metadata": {},
   "source": [
    "### create X_train,Y_train ,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07b95d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 50, 50, 1), (45, 3), (15, 50, 50, 1), (15, 3))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(traing)\n",
    "X_train=np.array([i[0] for i in traing]).reshape(-1,50,50,1)\n",
    "Y_train=np.array([i[1] for i in traing])\n",
    "\n",
    "X_test=np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
    "Y_test=np.array([i[1] for i in test])\n",
    "\n",
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9e4df",
   "metadata": {},
   "source": [
    "## start model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[50,50,1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "model.fit(X_train, y_train, n_epoch=12, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"Images for visualization\")):\n",
    "        path = os.path.join(\"Images for visualization\", img)\n",
    "        img_num = img.split('.')[0] \n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vdata = data_for_visualization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36811b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   # pip install matplotlib\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(50,50,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label = 'Ishwar'\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        my_label = 'Manish'\n",
    "    else:\n",
    "        my_label = 'Bijay'\n",
    "        \n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "    \n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553b460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
